\begin{abstract}
This project explores the use of Heavy Ball Gradient and Camerini-Fratta-Maffioli subgradient for training neural networks using L1 (Lasso) regularization. First, the learning problem of neural networks is formalized in a general optimization framework. Next, the two algorithms are analyzed extensively from a theoretical point of view, especially in terms of their convergence complexity. Finally, many experiments are run to appreciate the differences between them, discussing in depth their strengths and weaknesses in light of the obtained results.
\end{abstract}
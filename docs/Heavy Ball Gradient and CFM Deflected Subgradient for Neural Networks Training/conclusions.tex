In this chapter we explored the use of two different optimization algorithms for training MLPs using L1 regularization, the first one being Heavy Ball Gradient (HBG), and the second being Camerini-Fratta-Maffioli deflected subgradient (CFM).  

After a brief but consistent summary of the theoretical properties of the two, we run many experiments to compare them.

In \ref{exp01} we showed an interesting property of the target level in CFM, which also came up in \ref{exp2}: the faster the convergence of the target level, the faster the convergence of training, but the larger the final loss.

In \ref{exp02} we experimentally confirmed the convergence properties of CFM for convex objective functions, forcing the convexity of our loss by using the identity as activation function of the MLP. The results we got also show CFM superiority with respect to HBG when dealing with convex functions. This is especially true when an approximation of the best value of the loss is known, otherwise CFM might took longer than HBG, but in the long run would still achieve better results.

In \ref{exp1} and \ref{exp2} we tested CFM and HBG on respectively one hidden layer and two hidden layers MLPs, using ReLU and Sigmoid activation functions. HBG always outperformed CFM, having a faster and steadier conergence, especially in the case of Sigmoid. With Sigmoid, in fact, CFM was always found to have a very high variance, and could not achieve training losses as low as those achieved by HBG. In \ref{exp2} we also tried to use CFM with exact Polyak stepsize to train the MLP with ReLU activation function, but the results we got were not even remotely comparable to those achieved by HBG and CFM with target level, proving the need of convexity of the objective function for this algorithm to work effectively.

Eventually, in \ref{exp3} we tested HBG and CFM on a three hidden layers MLP. It turned out that in this case it would be CFM to outperform HBG, which did not seem capable of overcoming a local minimum. CFM, instead, even if with a higher variance of speed and optimality of the solution found, would almost always achieve a far better result.

Summing up, our experiments show that HBG is superior to CFM by far in training MLPs of low and medium sizes, in terms of variance, speed of convergence and flexibility with respect to the activation function. Still, when training bigger MLPs with ReLU activation function, CFM might be worthy of consideration, and would plausibly achieve much better results than HBG, whose effectiveness does not scale as well.
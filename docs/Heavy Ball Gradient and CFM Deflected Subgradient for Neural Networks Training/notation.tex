\subsection{Multi Layer Perceptrons (MLP)}
We consider a Multi Layer Perceptron (MLP) with $L$ layers. We will denote by $\W_l$ and by $\b_l$ respectively the weights matrix and the bias vector of layer $l$, so that the parameters matrix of the same layer, i.e. the concatenation of its bias vector with its weights matrix, will be $\theta_l = \left[\b_l, \W_l\right]$. The activation function of layer $l$ will be instead denoted by $f_l$, so that the output of layer $l$ will then be: $\o_l = f_l(\h_l)$, where $\h_l = \W_l\o_{l - 1} + \b_l$ is the net input of the layer. Finally, we will denote the parameters vector of the MLP, i.e. the concatenation of the flattened parameters matrices of its layers, as $\theta = \left[flat(\theta_1)^T, \ldots, flat(\theta_L)^T\right]^T$.

\subsection{Activation function}
We will consider two different activation functions. The first one is the Rectified Linear Unit (ReLU):
\[
    R(x) = \max(0, x),
\]
and the second one is the Sigmoid, or logistic function:
\[
    \sigma(x) = \frac{1}{1 + e^{-x}}.
\]
Both of them are continuous, but while the Sigmoid is differentiable, ReLU is not in $x = 0$; still, as usual when dealing with this activation function, we will assume $R'(0) = 0$ and ignore the issue.

\subsection{Objective function}
\label{obj_fun}
Consider a dataset $\D = (\X, \Y) $ consisting of $S$ samples, with input data $\x_i \in \X \subseteq \R^m$ and targets $\y_i \in \Y \subseteq \R^n$, for $i = 1, 2, \ldots, S$. A MLP with $m$ input units and $n$ output units defines a prediction function $\M_\theta: \R^m \rightarrow \R^n$, parametric in $\theta$. The training of a MLP aims to minimize an objective loss function
\[
J(\theta) = \L\left(\Y,\Yh\right) + \lambda\Omega(\theta),
\]
wher $\L\left(\Y, \Yh\right)$ is the error function between the true targets $\Y$ and the predicted targets $\Yh = \M_\theta(\X)$, and $\Omega(\theta)$ is the regularization term, which is weighted by the regularization hyperparameter $\lambda$.

As error function we will consider the Mean Squared Error (MSE):
\[
    \L\left(\Y, \Yh\right) = \frac{1}{2S} \left\Vert \Y - \Yh \right\Vert_2^2 = \frac{1}{2S} \sum_{i=1}^S \left(\y_i - \yh_i\right)^2,
\]
where $\yh_i = \M_\theta(\x_i)$.

As regularization function  we will consider the L1-regularization:
\[
    \Omega(\theta) = \sum_{l=1}^L \Vert \W_l \Vert_{1}
\]

Note that a loss function such defined is neither convex nor differentiable: non convexity is caused by the non linearity of the activation functions of the layers, non differentiability is caused by the 1-norm in the L1-regularization term.